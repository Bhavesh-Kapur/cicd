{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing all the necessary files and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Dropout,Flatten,Dense, Rescaling\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining constants throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "height = 150\n",
    "width = 150\n",
    "trainPath = '/Users/bhavesh/Documents/GitHub/cognition-3.0/Final-Project/archive/seg_train'\n",
    "testPath = '/Users/bhavesh/Documents/GitHub/cognition-3.0/Final-Project/archive/seg_test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Data Function \n",
    "This data function will be loading and preprocessing the data \n",
    "Preprocessing on the grounds of image size and batch_size\n",
    "\n",
    "And creating DataSets for model training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 files belonging to 6 classes.\n",
      "Found 3000 files belonging to 6 classes.\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
     ]
    }
   ],
   "source": [
    "def data(path,labels):\n",
    "    dataset = image_dataset_from_directory(\n",
    "        directory = path,\n",
    "        labels = labels,\n",
    "        seed = 123,\n",
    "        image_size=(height,width),\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "trainDS = data(trainPath, labels='inferred')\n",
    "testDS = data(testPath, labels='inferred')\n",
    "\n",
    "className = trainDS.class_names\n",
    "print(className) #analysis on the category "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = Rescaling(1./255)  #normalizing \n",
    "\n",
    "trainDS = trainDS.map(lambda x,y: (standard(x), y))\n",
    "testDS = testDS.map(lambda x,y: (standard(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "     tf.keras.Input(shape=(150,150,3)),\n",
    "     Conv2D(16,(3,3), activation='relu'),\n",
    "     MaxPooling2D(2,2),\n",
    "     Conv2D(32,(3,3), activation='relu'),\n",
    "     MaxPooling2D(2,2),\n",
    "     Conv2D(64,(3,3), activation='relu'),\n",
    "     MaxPooling2D(2,2),\n",
    "     Flatten(),\n",
    "     Dense(128, activation='relu'),\n",
    "     Dense(len(className),activation='softmax')\n",
    "\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 153ms/step - accuracy: 0.5603 - loss: 1.1237 - val_accuracy: 0.7417 - val_loss: 0.7191\n",
      "Epoch 2/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 105ms/step - accuracy: 0.7587 - loss: 0.6628 - val_accuracy: 0.7847 - val_loss: 0.5878\n",
      "Epoch 3/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 110ms/step - accuracy: 0.8102 - loss: 0.5217 - val_accuracy: 0.8090 - val_loss: 0.5594\n",
      "Epoch 4/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 106ms/step - accuracy: 0.8695 - loss: 0.3840 - val_accuracy: 0.8170 - val_loss: 0.5739\n",
      "Epoch 5/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 106ms/step - accuracy: 0.9003 - loss: 0.2798 - val_accuracy: 0.7940 - val_loss: 0.6850\n",
      "Epoch 6/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 111ms/step - accuracy: 0.9359 - loss: 0.1951 - val_accuracy: 0.8003 - val_loss: 0.7305\n",
      "Epoch 7/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 118ms/step - accuracy: 0.9603 - loss: 0.1252 - val_accuracy: 0.7950 - val_loss: 0.8638\n",
      "Epoch 8/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 108ms/step - accuracy: 0.9665 - loss: 0.0991 - val_accuracy: 0.7810 - val_loss: 0.9576\n",
      "Epoch 9/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 291ms/step - accuracy: 0.9772 - loss: 0.0705 - val_accuracy: 0.7920 - val_loss: 0.9643\n",
      "Epoch 10/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 269ms/step - accuracy: 0.9825 - loss: 0.0553 - val_accuracy: 0.8007 - val_loss: 1.1011\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit(trainDS, validation_data=testDS, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ultra.keras\n"
     ]
    }
   ],
   "source": [
    "model.save('ultra.keras') # type: ignore\n",
    "print(\"Model saved to ultra.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A prediction Script is below to predict any img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "The predicted class is: sea\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('ultra.keras')\n",
    "height = 150\n",
    "width = 150\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(height, width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  \n",
    "    img_array = img_array / 255.0  \n",
    "    return img_array\n",
    "\n",
    "def predict_image_class(img_path):\n",
    "    img_array = preprocess_image(img_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    return predicted_class[0]\n",
    "\n",
    "image_path = '/Users/bhavesh/Documents/GitHub/cognition-3.0/Final-Project/archive/seg_pred/4357.jpg'\n",
    "\n",
    "\n",
    "predicted_class = predict_image_class(image_path)\n",
    "\n",
    "class_names = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "print(f\"The predicted class is: {class_names[predicted_class]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
